\begin{thebibliography}{19}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Adv()]{AdvancedTopicsMachine}
Advanced {{Topics}} in {{Machine Learning}} ({{ATML}}).
\newblock URL \url{https://kurser.ku.dk/course/ndak15014u}.

\bibitem[All()]{AllstateClaimsSeverity}
Allstate {{Claims Severity}} - {{Fair Loss}}.
\newblock URL \url{https://kaggle.com/c/allstate-claims-severity}.

\bibitem[Dml()]{DmlcXgboost}
Dmlc/xgboost.
\newblock URL \url{https://github.com/dmlc/xgboost}.

\bibitem[HEP()]{HEPMeetsML}
{{HEP}} meets {{ML}} award | {{The Higgs Machine Learning Challenge}}.
\newblock URL \url{https://higgsml.lal.in2p3.fr/prizes-and-award/award/}.

\bibitem[Lar()]{LargeElectronPositronCollider}
The {{Large Electron}}-{{Positron Collider}} | {{CERN}}.
\newblock URL
  \url{https://home.cern/science/accelerators/large-electron-positron-collider}.

\bibitem[Abu-Mostafa et~al.()Abu-Mostafa, Magdon-Ismail, and
  Lin]{abu-mostafaLearningData2012}
Y.~S. Abu-Mostafa, M.~Magdon-Ismail, and H.-T. Lin.
\newblock \emph{Learning {{From Data}}}.
\newblock {AMLBook}.
\newblock ISBN 978-1-60049-006-4.

\bibitem[Anderson()]{andersonSpeciesProblemIris1936a}
E.~Anderson.
\newblock The {{Species Problem}} in {{Iris}}.
\newblock 23\penalty0 (3):\penalty0 457--509.
\newblock ISSN 00266493.
\newblock \doi{10.2307/2394164}.
\newblock URL \url{www.jstor.org/stable/2394164}.

\bibitem[Barron()]{barronGeneralAdaptiveRobust2017}
J.~T. Barron.
\newblock A {{General}} and {{Adaptive Robust Loss Function}}.
\newblock URL \url{http://arxiv.org/abs/1701.03077}.

\bibitem[Breiman()]{breimanRandomForests2001}
L.~Breiman.
\newblock Random {{Forests}}.
\newblock 45\penalty0 (1):\penalty0 5--32.
\newblock ISSN 1573-0565.
\newblock \doi{10.1023/A:1010933404324}.
\newblock URL \url{https://doi.org/10.1023/A:1010933404324}.

\bibitem[Chen and Guestrin()]{chenXGBoostScalableTree2016}
T.~Chen and C.~Guestrin.
\newblock {{XGBoost}}: {{A Scalable Tree Boosting System}}.
\newblock pages 785--794.
\newblock \doi{10.1145/2939672.2939785}.
\newblock URL \url{http://arxiv.org/abs/1603.02754}.

\bibitem[Fisher()]{fisherUseMultipleMeasurements1936}
R.~A. Fisher.
\newblock The {{Use}} of {{Multiple Measurements}} in {{Taxonomic Problems}}.
\newblock 7\penalty0 (2):\penalty0 179--188.
\newblock ISSN 2050-1439.
\newblock \doi{10.1111/j.1469-1809.1936.tb02137.x}.
\newblock URL
  \url{https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1469-1809.1936.tb02137.x}.

\bibitem[Freund and
  Schapire()]{freundDesiciontheoreticGeneralizationOnline1995}
Y.~Freund and R.~E. Schapire.
\newblock A desicion-theoretic generalization of on-line learning and an
  application to boosting.
\newblock In P.~Vit√°nyi, editor, \emph{Computational Learning Theory}, pages
  23--37. {Springer Berlin Heidelberg}.
\newblock ISBN 978-3-540-49195-8.
\newblock AdaBoost.

\bibitem[Hastie et~al.()Hastie, Tibshirani, and
  Friedman]{hastieElementsStatisticalLearning2009}
T.~Hastie, R.~Tibshirani, and J.~Friedman.
\newblock \emph{The {{Elements}} of {{Statistical Learning}}: {{Data Mining}},
  {{Inference}}, and {{Prediction}}, {{Second Edition}}}.
\newblock Springer {{Series}} in {{Statistics}}. {Springer-Verlag}, 2 edition.
\newblock ISBN 978-0-387-84857-0.
\newblock URL \url{//www.springer.com/la/book/9780387848570}.

\bibitem[Ke et~al.()Ke, Meng, Finley, Wang, Chen, Ma, Ye, and
  Liu]{keLightGBMHighlyEfficient2017}
G.~Ke, Q.~Meng, T.~Finley, T.~Wang, W.~Chen, W.~Ma, Q.~Ye, and T.-Y. Liu.
\newblock {{LightGBM}}: {{A Highly Efficient Gradient Boosting Decision Tree}}.
\newblock In I.~Guyon, U.~V. Luxburg, S.~Bengio, H.~Wallach, R.~Fergus,
  S.~Vishwanathan, and R.~Garnett, editors, \emph{Advances in {{Neural
  Information Processing Systems}} 30}, pages 3146--3154. {Curran Associates,
  Inc.}
\newblock URL
  \url{http://papers.nips.cc/paper/6907-lightgbm-a-highly-efficient-gradient-boosting-decision-tree.pdf}.

\bibitem[Tibshirani()]{tibshiraniRegressionShrinkageSelection1996}
R.~Tibshirani.
\newblock Regression {{Shrinkage}} and {{Selection}} via the {{Lasso}}.
\newblock 58\penalty0 (1):\penalty0 267--288.
\newblock ISSN 0035-9246.
\newblock URL \url{www.jstor.org/stable/2346178}.

\bibitem[Tikhonov()]{tikhonovStabilityInverseProblems1943}
A.~Tikhonov.
\newblock \emph{On the Stability of Inverse Problems}, volume vol. 39 of
  \emph{Doklady {{Akademii Nauk SSSR}}}.

\bibitem[van Veen()]{veenNeuralNetworkZoo2016}
F.~van Veen.
\newblock The {{Neural Network Zoo}}.
\newblock URL \url{http://www.asimovinstitute.org/neural-network-zoo/}.

\bibitem[Vapnik()]{vapnikPrinciplesRiskMinimization1991}
V.~Vapnik.
\newblock Principles of {{Risk Minimization}} for {{Learning Theory}}.
\newblock In \emph{Proceedings of the 4th {{International Conference}} on
  {{Neural Information Processing Systems}}}, {{NIPS}}'91, pages 831--838.
  {Morgan Kaufmann Publishers Inc.}
\newblock ISBN 978-1-55860-222-9.
\newblock URL \url{http://dl.acm.org/citation.cfm?id=2986916.2987018}.

\bibitem[Wickham()]{JSSv059i10}
H.~Wickham.
\newblock Tidy data.
\newblock 59\penalty0 (10):\penalty0 1--23.
\newblock ISSN 1548-7660.
\newblock \doi{10.18637/jss.v059.i10}.
\newblock URL \url{https://www.jstatsoft.org/v059/i10}.

\end{thebibliography}
